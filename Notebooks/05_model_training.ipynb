{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3435fb-d718-4d84-bfb6-c8870f8ed8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML Frameworks\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             ConfusionMatrixDisplay, roc_auc_score, accuracy_score)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Resampling for Imbalanced Data\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 5: PREDICTIVE MODELING & ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "# Importing the Enriched dataset\n",
    "df_1 = pd.read_csv('loan_data_enriched.csv')\n",
    "\n",
    "# --- 1. FEATURE SELECTION & DIMENSIONALITY REDUCTION ---\n",
    "# Objective: Remove high-cardinality identifiers, redundant data, and \n",
    "# features that introduce 'Data Leakage' (e.g., total_payment).\n",
    "to_remove = [\n",
    "    'id', 'address_state', 'application_type', 'emp_title', 'issue_date',\n",
    "    'last_credit_pull_date', 'last_payment_date', 'next_payment_date',\n",
    "    'loan_status', 'member_id', 'sub_grade', 'emp_length', 'annual_income',\n",
    "    'int_rate', 'dti', 'grade', 'installment', 'month', 'emp_length_num',\n",
    "    'risk_score', 'total_payment'\n",
    "]\n",
    "\n",
    "df_ml = df_1.drop(columns=to_remove, errors='ignore')\n",
    "\n",
    "# --- 2. PREPROCESSING & FEATURE TRANSFORMATION PIPELINES ---\n",
    "# Logic: Applying a dual-strategy to handle skewed distributions and outliers.\n",
    "\n",
    "# A. Logarithmic Normalization (Skewed Distributions)\n",
    "col_to_log = [\n",
    "    'loan_amount', 'total_acc', 'annual_income_capped', \n",
    "    'payment_to_income_ratio', 'loan_to_income_ratio'\n",
    "]\n",
    "\n",
    "# B. Scaler-Only (Uniform distributions)\n",
    "col_to_scale_only = ['payment_completion_ratio']\n",
    "\n",
    "# C. Categorical & Binary Handling\n",
    "cat_features = [\n",
    "    'home_ownership', 'purpose', 'term', 'verification_status',\n",
    "    'grade_numeric', 'dti_category', 'int_rate_category', \n",
    "    'tenure_tier', 'risk_segment'\n",
    "]\n",
    "binary_features = ['dti_rate_warning', 'int_rate_warning', 'is_60_months']\n",
    "\n",
    "# Constructing the ColumnTransformer\n",
    "# RobustScaler is utilized to mitigate the influence of financial outliers.\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_transform', Pipeline([\n",
    "            ('log', log_transformer),\n",
    "            ('scaler', RobustScaler())\n",
    "        ]), col_to_log),\n",
    "        ('std_scale', RobustScaler(), col_to_scale_only),\n",
    "        ('categorical', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features),\n",
    "        ('binary', 'passthrough', binary_features)\n",
    "    ])\n",
    "\n",
    "# --- 3. PIPELINE FACTORY (RESAMPLING & CLASSIFICATION) ---\n",
    "# Objective: Create a reproducible pipeline that integrates SMOTEENN \n",
    "# to address the 14% minority class (defaulted loans) within the CV loop.\n",
    "def create_credit_pipeline(classifier):\n",
    "    return Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('smoteen', SMOTEENN(random_state=42)), # Hybrid resampling to clean noise\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "# --- 4. DATA PARTITIONING (STRATIFIED SPLIT) ---\n",
    "X = df_ml.drop(columns=['defaulted'])\n",
    "y = df_ml['defaulted']\n",
    "\n",
    "# Utilizing stratify=y to ensure target proportion is preserved in training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 5. MODEL BENCHMARKING: CHAMPION VS. CHALLENGERS ---\n",
    "# Benchmarking Linear (Logistic Regression) vs. Ensemble (Random Forest/XGBoost) models.\n",
    "models = {\n",
    "    \"Logistic_Regression\": create_credit_pipeline(LogisticRegression(max_iter=1000, C=1.0)),\n",
    "    \"Random_Forest\": create_credit_pipeline(RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    \"XGBoost\": create_credit_pipeline(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# 6. CHAMPION MODEL EVALUATION: LOGISTIC REGRESSION (High Interpretability)\n",
    "# =============================================================================\n",
    "lr_pipeline = models[\"Logistic_Regression\"]\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_LR = lr_pipeline.predict(X_test)\n",
    "y_proba_LR = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- PERFORMANCE REPORT: LOGISTIC REGRESSION ---\")\n",
    "print(classification_report(y_test, y_pred_LR))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba_LR):.4f}\")\n",
    "\n",
    "# Visualizing Confusion Matrix for Capital Protection Assessment\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_LR, cmap='Blues')\n",
    "plt.title('Confusion Matrix - Credit Risk (Logistic Regression)')\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 7. MODEL INTERPRETABILITY (FEATURE COEFFICIENTS)\n",
    "# =============================================================================\n",
    "# 'Opening the Black Box' to identify the top risk escalators and mitigators.\n",
    "model_logic = lr_pipeline.named_steps['classifier']\n",
    "preprocessor_fitted = lr_pipeline.named_steps['preprocessing']\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    output_features = []\n",
    "    for name, transformer, columns in column_transformer.transformers_:\n",
    "        if name == 'remainder' and transformer == 'drop': continue\n",
    "        if hasattr(transformer, 'named_steps'):\n",
    "            transformer = transformer.named_steps[list(transformer.named_steps.keys())[-1]]\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            names = transformer.get_feature_names_out(columns)\n",
    "        else:\n",
    "            names = columns\n",
    "        output_features.extend(names)\n",
    "    return output_features\n",
    "\n",
    "feature_names = get_feature_names(preprocessor_fitted)\n",
    "feat_imp = pd.DataFrame({'feature': feature_names, 'coefficient': model_logic.coef_[0]})\n",
    "feat_imp['abs_coef'] = feat_imp['coefficient'].abs()\n",
    "feat_imp = feat_imp.sort_values(by='abs_coef', ascending=False)\n",
    "\n",
    "# Visualizing Risk Drivers\n",
    "top_15 = feat_imp.head(15)\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['crimson' if x > 0 else 'seagreen' for x in top_15['coefficient']]\n",
    "plt.barh(top_15['feature'], top_15['coefficient'], color=colors)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 15 Credit Risk Drivers (Logistic Regression Coefficients)\", fontweight='bold')\n",
    "plt.xlabel(\"Coefficient Weight (Direction of Impact)\")\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 8. STABILITY VALIDATION (CROSS-VALIDATION)\n",
    "# =============================================================================\n",
    "# Ensuring results are robust across different folds of the data.\n",
    "cv_metrics = ['recall', 'precision', 'f1', 'roc_auc']\n",
    "cv_results = cross_validate(lr_pipeline, X_train, y_train, cv=5, scoring=cv_metrics, n_jobs=-1)\n",
    "\n",
    "print(\"\\n--- 5-FOLD CROSS-VALIDATION SUMMARY ---\")\n",
    "print(f\"Mean Recall:    {cv_results['test_recall'].mean():.4f} (Stability: +/- {cv_results['test_recall'].std():.4f})\")\n",
    "print(f\"Mean Precision: {cv_results['test_precision'].mean():.4f}\")\n",
    "print(f\"Mean ROC-AUC:   {cv_results['test_roc_auc'].mean():.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. CHALLENGER MODEL EVALUATION: RANDOM FOREST\n",
    "# =============================================================================\n",
    "rf_pipeline = models[\"Random_Forest\"]\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_RF = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n--- PERFORMANCE REPORT: RANDOM FOREST ---\")\n",
    "print(classification_report(y_test, y_pred_RF))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, rf_pipeline.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_RF, cmap='Greens')\n",
    "plt.title('Confusion Matrix - Credit Risk (Random Forest)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
